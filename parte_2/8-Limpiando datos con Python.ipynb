{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Logo SENA](https://certificadossena.net/wp-content/uploads/2022/10/logo-sena-verde-svg-2022.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://certificadossena.net/wp-content/uploads/2022/10/logo-sena-verde-svg-2022.svg\" width=\"300\" height=\"300\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "\n",
    "<b>Precios de casas:</b>\n",
    "La plataforma Kaggle nos muestra una data de los precios de las casas, en este nos dan las propiedades de muchas casas y nos dan su precio de mercado o el precio tentativo.\n",
    "\n",
    "Tenemos varias columnas, por ejemplo, el tamaño del terreno en pies al cuadrado, tenemos el tipo de calle que está enfrente del terreno, tenemos, por ejemplo, el año en que fue construida, el tipo de techo. Entonces vienen todas estas propiedades de las diferentes casas y al principio tenemos el costo de la casa. Este es un costo dado en dólares.\n",
    "\n",
    "Este conjunto de datos nos ofrece cuatro archivos: train.csv, test.csv, data_description.txt y samples_submission.csv. Los que vamos a utilizar por el momento son train.csv y data_description, este porque tiene, de los dos archivos train y\n",
    "test, el conjunto más grande de datos, y data_description es una descripción de todas las columnas.\n",
    "\n",
    "\n",
    "https://www.kaggle.com/c/house-prices-advanced-regression-techniques\n",
    "\n",
    "#### Favor abrir el archivo data_description.txt, para comprender los datos suministrados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # Importar pandas\n",
    "import numpy as np # Importar Numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numpy es el paquete más básico pero poderoso para la computación científica y la manipulación de datos en Python. Nos permite trabajar con matrices y matrices multidimensionales.\n",
    "\n",
    "Página oficial: https://numpy.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/house-prices-advanced-regression-techniques/train.csv',index_col=0) # Se lee el archivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape # Analizar la forma que tiene el conjunto de datos. Filas y columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head() # Nos muestra algunas filas (5) y las columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe() # Datos generales del conjunto de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates() # Va a buscar si hay registros que están repetidos y si los hay los elimina.\n",
    "df.shape # verificar cuantos registros quedaron, si es el mismo de antes indica que no hay registros duplicados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## El objetivo de la limpieza de datos es eliminar todos los elementos que no nos sirvan y los elementos faltantes. ¿Por qué? Porque esto nos puede traer problemas a la hora de modelar y tratar de hacer predicciones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop NA\n",
    "\n",
    "### La función \"Drop NA\" permite eliminar los valores faltantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Borra todas las filas con NaN\n",
    "df.dropna() # ¿Analizar por qué da 0 filas?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head() # Nos muestra algunas filas (5) y las columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna() # Realiza una matriz indicando donde hay datos y donde no hay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sume los elementos que faltan por columna y ordenelos\n",
    "columnas_na = df.isna().sum().sort_values(ascending = False)\n",
    "round((columnas_na[columnas_na > 0 ] / len(df)) * 100 , 2) # Se multiplica por 100 para dar el valor en %"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todas las filas tienen al menos un valor nulo, por lo tanto se borra todo el dataframe.<br>\n",
    "Intentemos borrar columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_drop_1 = df.dropna(axis = 1) # axis= 0 busca por filas, axis=1 busca por columnas y borra las Null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_drop_1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¿Cuántas columnas se borraron?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_drop_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# la variable dfPiscina Se crea de tipo DataFrame\n",
    "dfPiscina = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfPiscina"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfPiscina va a tener una columna 'calidad_Piscina' que es de otro data frame (df)\n",
    "dfPiscina['calidad_Piscina'] = df['PoolQC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfPiscina # Se imprime la variable dfPiscina"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## ¿Y qué eliminamos de esa columna?\n",
    "### Analizando la columna **PoolQC**\n",
    "\n",
    "Según **data_description.txt**\n",
    "\n",
    "\n",
    "PoolQC: Pool quality\n",
    "\n",
    "       Ex\tExcellent\n",
    "       Gd\tGood\n",
    "       TA\tAverage/Typical\n",
    "       Fa\tFair\n",
    "       NA\tNo Pool\n",
    "       \n",
    "Borramos información vital en el DataFrame.\n",
    "\n",
    "En lugar de borrarla la podemos convertir en  una columna de datos  ordinales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['PoolQC'].unique() # Retorna los valores únicos en la columna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfPiscina['calidad_Piscina'].unique() # Retorna los valores únicos en la columna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se hace una conversión Ex va a ser 4, Gd va a ser 3.. nan a a ser 0\n",
    "poolQCvalues={'Ex':4,'Gd':3,'TA':2,'Fa':1,np.nan:0}\n",
    "\n",
    "# Se hace un mapeo donde el mapa es el que se acaba de definir\n",
    "df['PoolQC'] = df['PoolQC'].map(poolQCvalues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para la columna QC buscar los nulos y sumarlos\n",
    "print('Número de NaN en la columna:', df['PoolQC'].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample significa que va a traer 11 valores aleatorios. Recordar que el 99% eran nulos, ahora son 0\n",
    "df['PoolQC'].sample(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se traen de nuevo los valores únicos, esta vez son números (ordinales: Aumenta el valor, aumenta la calidad)\n",
    "df['PoolQC'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analizando la columna **CentralAir**\n",
    "\n",
    "CentralAir: Central air conditioning (La casa tiene aire acondicionado central)\n",
    "\n",
    "       N\tNo\n",
    "       Y\tYes\n",
    "En los datos estan los valores como N y Y, estas letras no son buenas a la hora de hacer modelado los algorítmos no trabajan correctamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['CentralAir'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se mapean los valores donde N=0 y la Y=1\n",
    "centralAirvalues={'N' : 0,'Y':1}\n",
    "\n",
    "# La columna CentralAir va a tomar el valor del mapa definido en el diccionario\n",
    "df['CentralAir'] = df['CentralAir'].map(centralAirvalues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['CentralAir'].sample(13) # Tomar 13 valores al azar para verificar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Electrical\n",
    "\n",
    "Electrical: Electrical system\n",
    "\n",
    "       SBrkr\tStandard Circuit Breakers & Romex\n",
    "       FuseA\tFuse Box over 60 AMP and all Romex wiring (Average)\t\n",
    "       FuseF\t60 AMP Fuse Box and mostly Romex wiring (Fair)\n",
    "       FuseP\t60 AMP Fuse Box and mostly knob & tube wiring (poor)\n",
    "       Mix\tMixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Electrical'].unique() # Los valores unicos de la columna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Número de NaN en la columna:', df['Electrical'].isna().sum()) # ¿Cuántos datos faltan?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solo un dato falta, se puede eliminar la fila o buscar por qué valor reemplazarlo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moda = df['Electrical'].mode()[0] # Calcular la moda de la columna Electrical\n",
    "print(moda) # Imprime el valor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Electrical'] = df['Electrical'].fillna(moda) # fillna: reemplazar por"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Número de NaN en la columna:', df['Electrical'].isna().sum()) # Se verifica cuantos valores faltan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Electrical'].unique() # Los valores unicos de la columna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Electrical'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Electrical'].sample(11) # "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### astype convierte una columna de texto a categoria osea asignar un valor númerico, pero lo malo es que no se sabe que números se asignan. Es otra manera de hacerlo y no usar mapeos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Electrical'] = df['Electrical'].astype('category').cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Electrical'].head() # El resultado indica que a Sbrkr asigno un valor de ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No existe una relación de orden en la columna **Electrical**, por lo tanto estas  categorias no tiene mucho sentido analizarlo como una variable ordinal, deberiamos mejor convertirlas a **Dummy Variables**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cuartiles y  datos atípicos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limpieza por cuartiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los cuartiles son valores que dividen una muestra de datos en cuatro partes iguales. Con los cuartiles se puede evaluar rápidamente la dispersión y la tendencia central de los datos.\n",
    "\n",
    "### Para crear los cuartiles:\n",
    "https://youtu.be/24Uz1mBksL4?si=mIr77lv_LshlOlfF\n",
    "\n",
    "El recuadro se extiende desde los valores de cuartil Q1 a Q3 de los datos, con una línea en la mediana (Q2). Los **bigotes** se extienden desde los bordes de la **caja** para mostrar el rango de los datos. \n",
    "La posición de los **bigotes** se establece de forma predeterminada en 1.5 * IQR (IQR = Q3 - Q1) desde los bordes de la caja. (IQR: Rango intercuartílico)\n",
    "\n",
    "Los puntos atípicos son aquellos que se encuentran más allá del final de los bigotes.\n",
    "\n",
    "### Construyendo la caja:\n",
    "https://youtu.be/lefGOMFbI90?si=Et-q020NZqaJe2aF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#En versiones anteriores primero va esta linea de código\n",
    "#%matplotlib inline\n",
    "df.boxplot('SalePrice') # Gráfica de Caja para la columna o varible SalePrice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lo que nos dice la gráfica es que la mayoría de los datos se encuentran entre 120 mil dólares a 210 mil dólares por dar un estimado, esto es lo que se encuentra dentro de la caja.\n",
    "#### Del bigote superior al bigote de abajo representa el grueso de nuestros datos.\n",
    "#### Es decir, 1.5 veces el rango inter cuartil.\n",
    "#### Lo que se encuentre fuera de ese rango son datos que podemos considerar aislados, entonces todos estos datos es posible que requieran limpieza."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtener el precio de venta y guardarlo en una variable.\n",
    "sP = df['SalePrice']\n",
    "IQR = 1.5*(sP.quantile(.75)-sP.quantile(.25)) # Rango inter cuartil\n",
    "lim_sup = sP.quantile(.75)+IQR # Hasta donde llega el primer bigote\n",
    "lim_inf = sP.quantile(.25)-IQR # Hasta donde llega el bigote de abajo o limite inferior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Listar los valores que esten por encima del límite o los que esten por debajo\n",
    "sP_clean = sP[(sP >= lim_sup) | (sP <= lim_inf)]\n",
    "sP_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.drop(sP_clean.index) # Se eliminan los valores atípicos por el ID (index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limpieza por desviación estandar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La desviación estándar es una de las medidas de estadística más populares y de mayor uso. Esta medida indica el grado de dispersión alrededor de la media. Una desviación grande indica datos muy dispersos y una desviación pequeña indica un menor grado de dispersión.\n",
    "\n",
    "El puntaje Z (**Z -score**) es el número de desviaciones estándar por las cuales el valor de una observación está por encima del valor medio de lo que se está observando."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# stats nos da un conjunto de medidas estaditicas para ser usadas desde python\n",
    "from scipy import stats\n",
    "sP = df['SalePrice'] # Trabajar con la columna Precio de Venta\n",
    "z = np.abs(stats.zscore(sP)) # zscore: Distribución normal\n",
    "z # Imprime los valores que estan por arriba o abajo de la media arítmetica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sP_clean = sP[(z>3) | (z<-3)] # Tomar las medidas que esten 3 ditribuciones normales arriba o abajo\n",
    "df.drop(sP_clean.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observar que aquí quedaron con 1,438 rows, o filas, mientras que en el anterior quedó con 1,460. En cada una de las diferentes formas de eliminar los valores atípicos funciona de forma diferente por lo tanto no van a quedar los mismos conjuntos.\n",
    "\n",
    "### Esta decisión de cuál utilizar, uno u otro, dependera del modelo de estudio que estemos haciendo. Dependerá mucho de los resultados que nos den nuestros modelos predictivos y ese sera uno de los posibles ajustes que podemos hacer en caso que queremos mejorar o empeorar un poquito la calidad para estar ajustandolo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### Taller:\n",
    "\n",
    "Contexto: Dado que el surf nació en la costa oeste de EEUU, se plantea que el mayor número de ataques de tiburones a surfistas se ha producido en la costa oeste de EEUU.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importar módulos\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creación de la base de datos\n",
    "# Solucionar el error de UTF8b\n",
    "\n",
    "df = pd.read_csv(\"data/GSAF5.csv\")\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Despues de buscar varias soluciones para intentar corregir el archivo\n",
    "Pude encontrar que todos los registros se encontraban en una sola linea \n",
    "la primera opcion que tome en cuenta fue crear un script en python que hiciera el trabajo de limpieza y realizara los complementos de los complementos de los registros o almacenara en un area de stagin los registros que no estuvieran de acuerdo con los encabezados.\n",
    "\n",
    "Pero luego teniendo en cuenta de que el problema era por la organizacion del archivo que pandas no me lo dejaba leer me surgio la idea de convertir el archivo a HTML para poder verlo como un archivo de tipo json, entonces transforme el archivo a HTML y puede ver que todos los registros estaban en una sola linea y esto era lo que entorpecia el pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use el siguiente recurso para realizar la conversion\n",
    "https://tableconvert.com/csv-to-html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install lxml\n",
    "# !pip install html5lib\n",
    "from io import StringIO\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Despues de identificar que el archivo estaba organizado en una sola fila\n",
    "entonces accedemos a la unica tabla que tiene el archivo html la cual se encuentra en\n",
    "la posicion 0\n",
    "\"\"\"\n",
    "df_init = pd.read_html(\"data/GSAF5.html\")\n",
    "table_df = df_init[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limpieza del archivo\n",
    "\"\"\"\n",
    "El procedimiento fue sencillo se aplicaron los siguientes metodos\n",
    ".iloc[:, 0] Se encarga de tomar la primera columna completa \n",
    ".dropna() Elimina valores nulos en los registros\n",
    ".tolist() Se encarga de convertir la columna una lista de string donde\n",
    "cada fila representa una fila de datos \n",
    "\"\"\"\n",
    "rows = table_df.iloc[:, 0].dropna().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funcion para separar los registros  \n",
    "'''\n",
    "Luego de poder acceder a los datos de mi db y tener los encabezados listos \n",
    "cree una funcion que se encargara de separar los datos para tener los registros\n",
    "organizados segun las respectivas columnas utilice una expresion regular para evitar\n",
    "dividir comas que esten dentro de comillas\n",
    "\n",
    "val.strip().strip('\"') Con esto limpio los espacios sobrantes y comillas\n",
    "re.split(...) Parte el string en cada coma solo si esa coma no esta dentro de comillas \n",
    "dobles'''\n",
    "def smart_split(line):\n",
    "    f = StringIO(line)\n",
    "    reader = csv.reader(f)\n",
    "    for row in reader:\n",
    "        return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicacion de la funcion para todos los registros\n",
    "parsed = []\n",
    "for row in rows:\n",
    "    result = smart_split(row)\n",
    "    parsed.append(result)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separo encabezados de los datos\n",
    "headers = parsed[0]\n",
    "data = parsed[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajusto el numero de columnas \n",
    "max_cols = len(headers)\n",
    "clean_df = []\n",
    "\n",
    "for row in data:\n",
    "    recortado = row[:max_cols]\n",
    "    clean_df.append(recortado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creo Data Frame final \n",
    "df = pd.DataFrame(clean_df, columns=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Case Number</th>\n",
       "      <th>Date</th>\n",
       "      <th>Year</th>\n",
       "      <th>Type</th>\n",
       "      <th>Country</th>\n",
       "      <th>Area</th>\n",
       "      <th>Location</th>\n",
       "      <th>Activity</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>...</th>\n",
       "      <th>Species</th>\n",
       "      <th>Investigator or Source</th>\n",
       "      <th>pdf</th>\n",
       "      <th>href formula</th>\n",
       "      <th>href</th>\n",
       "      <th>Case Number</th>\n",
       "      <th>Case Number</th>\n",
       "      <th>original order</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016.09.18.c</td>\n",
       "      <td>18-Sep-16</td>\n",
       "      <td>2016</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>USA</td>\n",
       "      <td>Florida</td>\n",
       "      <td>New Smyrna Beach, Volusia County</td>\n",
       "      <td>Surfing</td>\n",
       "      <td>male</td>\n",
       "      <td>M</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>Orlando Sentinel, 9/19/2016</td>\n",
       "      <td>2016.09.18.c-NSB.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>2016.09.18.c</td>\n",
       "      <td>2016.09.18.c</td>\n",
       "      <td>5993</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016.09.18.b</td>\n",
       "      <td>18-Sep-16</td>\n",
       "      <td>2016</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>USA</td>\n",
       "      <td>Florida</td>\n",
       "      <td>New Smyrna Beach, Volusia County</td>\n",
       "      <td>Surfing</td>\n",
       "      <td>Chucky Luciano</td>\n",
       "      <td>M</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>Orlando Sentinel, 9/19/2016</td>\n",
       "      <td>2016.09.18.b-Luciano.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>2016.09.18.b</td>\n",
       "      <td>2016.09.18.b</td>\n",
       "      <td>5992</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016.09.18.a</td>\n",
       "      <td>18-Sep-16</td>\n",
       "      <td>2016</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>USA</td>\n",
       "      <td>Florida</td>\n",
       "      <td>New Smyrna Beach, Volusia County</td>\n",
       "      <td>Surfing</td>\n",
       "      <td>male</td>\n",
       "      <td>M</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>Orlando Sentinel, 9/19/2016</td>\n",
       "      <td>2016.09.18.a-NSB.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>2016.09.18.a</td>\n",
       "      <td>2016.09.18.a</td>\n",
       "      <td>5991</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016.09.17</td>\n",
       "      <td>17-Sep-16</td>\n",
       "      <td>2016</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>AUSTRALIA</td>\n",
       "      <td>Victoria</td>\n",
       "      <td>Thirteenth Beach</td>\n",
       "      <td>Surfing</td>\n",
       "      <td>Rory Angiolella</td>\n",
       "      <td>M</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>The Age, 9/18/2016</td>\n",
       "      <td>2016.09.17-Angiolella.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>2016.09.17</td>\n",
       "      <td>2016.09.17</td>\n",
       "      <td>5990</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016.09.15</td>\n",
       "      <td>16-Sep-16</td>\n",
       "      <td>2016</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>AUSTRALIA</td>\n",
       "      <td>Victoria</td>\n",
       "      <td>Bells Beach</td>\n",
       "      <td>Surfing</td>\n",
       "      <td>male</td>\n",
       "      <td>M</td>\n",
       "      <td>...</td>\n",
       "      <td>2 m shark</td>\n",
       "      <td>The Age, 9/16/2016</td>\n",
       "      <td>2016.09.16-BellsBeach.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>2016.09.16</td>\n",
       "      <td>2016.09.15</td>\n",
       "      <td>5989</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Case Number       Date  Year        Type    Country      Area  \\\n",
       "0  2016.09.18.c  18-Sep-16  2016  Unprovoked        USA   Florida   \n",
       "1  2016.09.18.b  18-Sep-16  2016  Unprovoked        USA   Florida   \n",
       "2  2016.09.18.a  18-Sep-16  2016  Unprovoked        USA   Florida   \n",
       "3    2016.09.17  17-Sep-16  2016  Unprovoked  AUSTRALIA  Victoria   \n",
       "4    2016.09.15  16-Sep-16  2016  Unprovoked  AUSTRALIA  Victoria   \n",
       "\n",
       "                           Location Activity             Name Sex   ...  \\\n",
       "0  New Smyrna Beach, Volusia County  Surfing             male    M  ...   \n",
       "1  New Smyrna Beach, Volusia County  Surfing   Chucky Luciano    M  ...   \n",
       "2  New Smyrna Beach, Volusia County  Surfing             male    M  ...   \n",
       "3                  Thirteenth Beach  Surfing  Rory Angiolella    M  ...   \n",
       "4                       Bells Beach  Surfing             male    M  ...   \n",
       "\n",
       "    Species        Investigator or Source                        pdf  \\\n",
       "0             Orlando Sentinel, 9/19/2016       2016.09.18.c-NSB.pdf   \n",
       "1             Orlando Sentinel, 9/19/2016   2016.09.18.b-Luciano.pdf   \n",
       "2             Orlando Sentinel, 9/19/2016       2016.09.18.a-NSB.pdf   \n",
       "3                      The Age, 9/18/2016  2016.09.17-Angiolella.pdf   \n",
       "4  2 m shark           The Age, 9/16/2016  2016.09.16-BellsBeach.pdf   \n",
       "\n",
       "                                        href formula  \\\n",
       "0  http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "1  http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "2  http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "3  http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "4  http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "\n",
       "                                                href   Case Number  \\\n",
       "0  http://sharkattackfile.net/spreadsheets/pdf_di...  2016.09.18.c   \n",
       "1  http://sharkattackfile.net/spreadsheets/pdf_di...  2016.09.18.b   \n",
       "2  http://sharkattackfile.net/spreadsheets/pdf_di...  2016.09.18.a   \n",
       "3  http://sharkattackfile.net/spreadsheets/pdf_di...    2016.09.17   \n",
       "4  http://sharkattackfile.net/spreadsheets/pdf_di...    2016.09.16   \n",
       "\n",
       "    Case Number original order      \n",
       "0  2016.09.18.c           5993      \n",
       "1  2016.09.18.b           5992      \n",
       "2  2016.09.18.a           5991      \n",
       "3    2016.09.17           5990      \n",
       "4    2016.09.15           5989      \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Year'] = pd.to_numeric(df['Year'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5685, 24)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Conocer la base de datos shape\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Case Number                  0\n",
       "Date                         2\n",
       "Year                        10\n",
       "Type                         2\n",
       "Country                      2\n",
       "Area                         2\n",
       "Location                     2\n",
       "Activity                     2\n",
       "Name                         4\n",
       "Sex                         15\n",
       "Age                         15\n",
       "Injury                      15\n",
       "Fatal (Y/N)                 79\n",
       "Time                        79\n",
       "Species                     79\n",
       "Investigator or Source      91\n",
       "pdf                       1403\n",
       "href formula              1406\n",
       "href                      1406\n",
       "Case Number               1406\n",
       "Case Number               1406\n",
       "original order            1406\n",
       "                          1406\n",
       "                          1406\n",
       "dtype: int64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Conocer cuántos registros nulos hay en cada columna isnull().sum()\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Case Number', 'Date', 'Year', 'Type', 'Country', 'Area', 'Location', 'Activity', 'Name', 'Sex ', 'Age', 'Injury', 'Fatal (Y/N)', 'Time', 'Species ', 'Investigator or Source', 'pdf', 'href formula', 'href', 'Case Number', 'Case Number', 'original order', '', '']\n"
     ]
    }
   ],
   "source": [
    "#Listar las columnas\n",
    "columnas = list(df.columns)\n",
    "print(columnas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comprobamos que hay columnas que tienen espacio en el nombre. \n",
    "#Eliminar el espacio de aquellos con la función str.rstrip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Seleccionar las columnas necesarias para el estudio:\n",
    "#Case Number, Country, Area, Date, Year, Location, Activity, 'Injury', 'Fatal (Y/N)'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Revisar si existen duplicados en la columna 'Case Number' (duplicated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Existen 16 'Case Number' duplicados. BORRARLOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comprobar que no hay registros duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filtrar el DataFrame solo por la actividad 'Surfing'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Conocer cuántos ataques a surfistas ha habido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Conteo de ataques a surfistas por países"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hacer una gráfica con los 5 países con mayor registro de ataques por tiburón.\n",
    "\n",
    "%matplotlib inline\n",
    "#surf_df.Country.value_counts().nlargest(5).plot.pie(labels=['....."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Seleccionar las regiones de la costa oeste de USA. Areas: Alaska, Hawai, California, Oregon y Washington\n",
    "\n",
    "#surf_west = surf_df.loc[(surf_df.Area.isin(('Alaska'......\n",
    "surf_west.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Contar ataques de tiburón a surfistas en el resto del mundo\n",
    "\n",
    "#surf_out = surf_df.loc\n",
    "surf_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Buscar los áreas donde mayor número de ataques se han producido a surfistas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Florida es el área donde mayor número de ataques a surfistas se han producido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gráfico para saber en qué áreas se producen más ataques a surfistas (graficar lo anterior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar los siguientes dataframes en archivos CSV\n",
    "surf_df.to_\n",
    "surf_west.to_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Revisar los ataques que tengan una 'Activity' no registrada (actividad isnull)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cerca de 527 ataques no indican cuál fue la 'Activity'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comente la siguinete liena de código\n",
    "shark_df[(shark_df['Activity'] == 'Surfing')]['Injury'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interprete los datos anteriores:\n",
    "#FATAL\n",
    "#Foot bitten\n",
    "#Left foot bitten\n",
    "#No injury, board bitten\n",
    "#...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basados en el grafico de ataques por países, filtrar por costa oeste y costa este,\n",
    "#cual de las dos presenta menor numero de ataques a surfistas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
